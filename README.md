# Whale_defined
Kaggle: Humpback Whale Challenge

Humpack_whale_challenge.ipynb - 2017 competition solution
....ipynb - 2018 competition solution. Performs much better than previous year, utilizes new siamese approach


## The 2018 solution document
This solution approach is guided by https://www.kaggle.com/martinpiotte/whale-recognition-model-with-score-0-78563. For details check out the link. 

This solution is derived from Siamese Neural Networks, with a few modifications. Each training epoch is composed of a sequence of image pairs (A,B) such that
* eactly 50% are for matching whales, 50% for different whales
* each image is used exactly 4 times per epoch, A and B images of matching whales, A and B of different whales
* Pairs are selected to be difficult for hte network to distinnguish, this forces the network to learn more sphisticated. This approahc is derived from adversarial training approach.

Data preprocessing:
* selecting correct pairs of whales
* rotate images as needed such as all the whal flukes are pointing in the same direction
* Black and White transform
* Affine transformation

The neural network architecture:
* ResNext50 as base encoder model
* refer to the CNN that encodes images into latent vector of features as the branch model
* refer to the model that compares feature vectors as the head model to determine if the whales match or not

The head model:
* ""The head model compares the feature vector from the branch model to decide if the pictures show the same or different whales. The typical approach is to use a distance measure (e.g.  L1 ) with a contrastive loss function, but there are a few reasons to try something different:

A distance measure will consider two features with value zero as a perfect match, while two features with large but slightly different values will be seen as good, but not quite as good since they are not exactly equal. Still, I feel there is more postive signal in the active features than in the negative ones, especially with ReLU (Rectified Linear Unit) activation, concept that is lost by the distance measure.
Also, a distance measure does not provide for features to be negatively correlated. Consider a case where, if both images have feature X, they must be the same whale, unless they also both have feature Y, in which case X is not as clear.
At the same time, there is this implicit assumption that swapping the two images must produce the same result: if A is the same whale as B, B must be the same whale as A.
* Thus our approach is: For each feature compute sum, product, abs diff, and the diff squared. Then pass the four values of a NN that can learn to weigh between matching zeros and close non-zero values. The same NN with same weights is used for each feature.
* The output gives weightsum sum of converted features, finally followed by sigmoid function. 

Training data constructiom - significantly influences model accuracy:
* The SNN needs to pick one correct whale from all possible whales, thus needs to score the correct whales high while ensuring the all the other whales are scored lower. 
* To acheive this, the training algorithm presents pairs at increasing difficulty as evaluated by model
* At the same time, SNN needs to recognize whales and not pictures.
* The data presented to model thus must be unbiased. This menas if a picture is used more often in negative examples, the model risks to simply learning to guess a mismatch whenever that picture is present. 
* This is resolved by presenting each image an equal number of times

Different whale examples:
Different whales examples are generated by computing a derangement of all pictures from the training set, subject to:

The image pairs must belong to different whales;
The pairs formed must be difficult for the model to distinguish.
The following algorith is used to generate the pairs:

The similarity between each pair of image is computed using the current model state. This has complexity  n(n−1)2 , where n is the size of the training set. Fortunately, only the head model must be computed for all pairs, and it is very fast. The 512-feature vectors can be pre-computed once for each image, i.e. O(n) complexity.
Entry that correpond to pair of images from the same whale are set with similarity  −∞ .
Linear sum assignment algorithm is used to find the most difficult matching.
To randomize the selection, and control the matching difficulty, we add a random matrix to the cost matrix from step #1 . The random matrix has values uniformly distributed between 0 and K. The larger K, the more random the matching. The smaller K, the more difficult the pairing is for the model.
To produce different matching for successive epochs, the selected entries in the matrix are overwritten with  −∞  to force an alternate selection for the next matching.

Training procedure:
* finetune learning rate, L2 regularization, K measuring the scale to preesnt tough training cases
* If example is too difficult, model will not converge at all
* Thus early training with high K, decrease K as we progress
* Introduce L2 as we train to prevent overfitting

